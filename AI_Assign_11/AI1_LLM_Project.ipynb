{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZfw6hVQh0Cv"
   },
   "source": [
    "# Deep Dive into Deep Learning: Fine-tuning a Large Language Model for Housing Price Prediction\n",
    "\n",
    "**Welcome to the world of Large Language Models!**\n",
    "\n",
    "In this project, you'll get a hands-on in building a state-of-the-art AI system capable of predicting housing prices. This challenge will immerse you in the core concepts of modern Natural Language Processing (NLP).\n",
    "\n",
    "## Prerequisites: A Foundation for Exploration\n",
    "\n",
    "This project assumes a basic familiarity with Python programming and Machine Learning.  While prior experience with deep learning libraries is beneficial, it's not strictly required, as we'll guide you through the essential concepts and techniques.\n",
    "\n",
    "**Here's a breakdown of the key prerequisites and resources to help you get started:**\n",
    "\n",
    "### 1. Machine Learning and Deep Learning:  The Power of Pattern Recognition\n",
    "\n",
    "*   **Machine Learning: From the Data Up**\n",
    "  \n",
    "  Machine learning algorithms grow models that realize rules and patterns from data without explicit programming. That is, instead of implementing rules based on human knowledge, we feed these algorithms large datasets, allowing them to identify trends on their own, with little expert's involvement. The aim of doing Machine Learning is to make predictions that are consistent with past and future observations.\n",
    "*   **Deep Learning: A Revolution in Artificial Intelligence**\n",
    "\n",
    "  Deep learning represents a powerful subset of machine learning that utilizes artificial neural networks – with computational structures inspired by the human brain – to model intricate patterns and relationships within data.  Deep learning has driven remarkable breakthroughs in computer vision, natural language processing, and countless other domains.\n",
    "    *   **Further Reading:** [Deep Learning](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville provides a comprehensive introduction to the field.\n",
    "\n",
    "### 2. The Natural Language Modeling Task: Teaching Machines to Understand Human Language\n",
    "\n",
    "*   **Decoding the Essence of Language**\n",
    "\n",
    "  Natural language processing (NLP) focuses on bridging the gap between human language and computer understanding. It encompasses a wide range of tasks, from simple text classification to machine translation and question answering.\n",
    "*   **The Power of Deep Learning in NLP**\n",
    "\n",
    "  Deep learning models, particularly those based on the Transformer architecture (more on that below!), have revolutionized NLP. Their ability to capture long-range semantic dependencies and intricate syntactic structures has led to significant improvements in language understanding and generation.\n",
    "    *   **Further Reading:**  The Stanford CS224N course ([Website](http://web.stanford.edu/class/cs224n/)) offers slides and notes that serve as a fantastic deep dive into NLP with deep learning.\n",
    "\n",
    "### 3. Transformers: The Architecture Reshaping NLP\n",
    "\n",
    "*   **Beyond Recurrent Networks**\n",
    "\n",
    "  Traditional recurrent neural networks (RNNs) faced challenges in processing long sequences of text due to their sequential nature. Transformers, introduced in the groundbreaking paper \"Attention Is All You Need\" ([Paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)), addressed these limitations by leveraging an innovative self-attention mechanism.\n",
    "*   **Attention is All You Need**  \n",
    "\n",
    "  Self-attention allows the model to weigh the importance of different words in a sentence when processing information, enabling it to capture relationships and dependencies across long distances efficiently. This breakthrough architecture has become the workhorse of modern NLP solutions.\n",
    "\n",
    "  We will be working with the T5 model in this project. It is a generic encoder-decoder Transformer model commonly used by researchers and academics to study the extend of machine language modeling.\n",
    "\n",
    "### 4. Hugging Face, PyTorch, and the Power of Open-Source AI\n",
    "\n",
    "*   **Hugging Face Transformers: Your Gateway to NLP**\n",
    "\n",
    "  Hugging Face provides a powerful and user-friendly library ([Hugging Face Documentation](https://huggingface.co/docs/transformers/index)) that simplifies the use of pre-trained Transformer models for various NLP tasks.  You'll use it extensively throughout this project.\n",
    "*   **PyTorch: A Powerful Auto-Diff Framework**\n",
    "\n",
    "  PyTorch is a widely adopted deep learning framework known for its dynamic computation graph and intuitive API. Its auto-differentiation capabilities streamline the process of calculating gradients, a critical aspect of training large neural networks with complex computation structures.\n",
    "    *   **Further Reading:**  The official [PyTorch Tutorials](https://pytorch.org/tutorials/) are an excellent resource for getting started.\n",
    "\n",
    "### 5. The Deep Learning Training Pipeline: A Step-by-Step Guide\n",
    "\n",
    "1.  **Data Preparation:**  Transforming raw data into a format suitable for training a deep learning model, often involving cleaning missing or invalid data values, data normalization, and splitting into training, validation, and test sets.\n",
    "2.  **Model Selection:** Choosing an appropriate model architecture (in our case, a pre-trained Transformer) based on the task/dataset characteristics. This is where the expert's intuition comes in, but at a very high level.\n",
    "3.  **Loss Function and Optimizer:** Defining a loss function that continuously quantifies the model's errors during training and selecting an optimization algorithm (typically Stochastic Gradient Descent and variations) to adjust the model's parameters and minimize this loss function.\n",
    "4.  **Training:** Feeding the training data through the model - in batches or all at once, calculating the loss, and using backpropagation to update the model's weights. We typically need to do these steps many times.\n",
    "5.  **Validation:**  Evaluating the model's performance on a separate validation set to tune hyperparameters and prevent overfitting (where the model memorizes the training data so it fails to generalize to unseen examples).\n",
    "6.  **Testing:** Assessing the model's final performance on a held-out test set to provide an unbiased estimate of its generalization correctness. These test examples should not have been used in tuning the model's parameters nor its hyperparameters.\n",
    "\n",
    "### 6. Project Goals: Unveiling the Apparent Magic of Deep Learning\n",
    "\n",
    "In this project, our aim is to provide you with practical experience and a deeper understanding of:\n",
    "\n",
    "*   **Fine-tuning Pretrained Language Models:** You'll learn how to adapt a powerful pre-trained language model (T5) to a specific task, scientific question answering, by training it on a relevant dataset.\n",
    "*   **Hyperparameter Tuning:** Experimenting with different training settings to optimize your model's performance.\n",
    "*   **Evaluating Model Performance:** Using appropriate metrics to assess your model's effectiveness.\n",
    "*   **Model Interpretability:** Gaining insights into how your model makes decisions, particularly by visualizing the attention mechanism within the Transformer architecture.\n",
    "\n",
    "**To be successful at this project's learning goals, we expect that you read the description of each section, run every code block sequentially from top to bottom (you can check if your implementation is correct by compare and contrast with the provided outputs), and complete the TODOs and final report. In addition, we highly encourage you to break free from the provided starter code and implement additional features for data augmnetation, model interpretability and visualization, etc. Happy deep diving!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrtlB17HhIhY",
    "outputId": "9a142501-8630-4793-ca27-2ff38072c3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sudha\\anaconda3\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sudha\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: torch in c:\\users\\sudha\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "    -------------------------------------- 20.5/992.0 kB 330.3 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 92.2/992.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 634.9/992.0 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 992.0/992.0 kB 6.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers tqdm torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aJGPc-OHwx--"
   },
   "outputs": [],
   "source": [
    "import os # For interacting with the operating system\n",
    "import pandas as pd # For data storage, manipulation, and fast analysis\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # For the T5 model\n",
    "from torch.utils.data import Dataset, DataLoader # For making custom datasets\n",
    "from tqdm import tqdm # For visualizing training/testing progress bar\n",
    "import torch # PyTorch library for deep learning\n",
    "import sklearn # For fast initialization of machine learning models and algorithms\n",
    "import matplotlib.pyplot as plt # For plotting graphs\n",
    "import seaborn as sns # For plotting heatmaps\n",
    "import warnings # For printing warning messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTSVPXxMhSzF"
   },
   "source": [
    "# Part 1: Data Preparation & Preprocessing\n",
    "1. Load the Boston Housing Dataset\n",
    "\n",
    "Download the [Boston Housing Dataset](https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/input), upload it to your Colab environment, and use the correct path name to programmatically access that file (should be a csv file) during runtime. If you would like to learn what the column names mean or the dataset origin, please visit [this link](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) (it is highly recommended that you intimately understand the dataset you are working with).\n",
    "\n",
    "Remember that our task is to train a model that can predict the price of houses given other attributes/features of those houses. That is, the last column of this data is what we aim to make the model correctly predict given the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpXyjjaxhfMr",
    "outputId": "fc25f45b-4a0e-4070-8881-52a62146123c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  MEDV  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n",
      "\n",
      "Dataset dimensions: (506, 14)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('./housing.csv', header=None, delimiter=r\"\\s+\", names=column_names) # Replace with the appropriate path if necessary\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(data.head()) # Display the first few rows of the dataset\n",
    "print()\n",
    "print(\"Dataset dimensions:\", data.shape) # Display the number of rows and columns in the dataset\n",
    "print()\n",
    "print(data.info()) # Display information about the dataset (data types, missing values of each column, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--va-j6DhwTX"
   },
   "source": [
    "2. Define a function to transform the dataset\n",
    "\n",
    "If you have been in Machine Learning for some time, you might have notice that price prediction is a regression task, which means the model should output continuous numerical values. However, T5 is a language model, which means it outputs discrete text tokens. We will handle this discrepancy in modality in the later section. For now, we need to convert the given numerical data format to the textual data format so our T5 model can consume this data.\n",
    "\n",
    "We need to do the following data processing steps:\n",
    "-  Combining Text: We combine the features into a single text string because the T5 model expects a single natural language string as input. The T5 model also outputs a single natural language string so we also need to make the ground-truth label a text string so we can supervise the model outputs versus the ground-truth labels.\n",
    "- Pandas DataFrame: We convert this data into a [Pandas DataFrame](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) for efficient data manipulation and to easily feed the data into our training pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x_qffxrnhtwv"
   },
   "outputs": [],
   "source": [
    "def reformat_dataset(data: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    formatted_data = []\n",
    "    for _, row in data.iterrows():\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: create the input string from part of the values in 'row'.\n",
    "        # You must not give the model the last column value\n",
    "        # as that is what we want the model to predict.\n",
    "        input_string = (\n",
    "            f\"CRIM: {row['CRIM']}, ZN: {row['ZN']}, INDUS: {row['INDUS']}, \"\n",
    "            f\"CHAS: {row['CHAS']}, NOX: {row['NOX']}, RM: {row['RM']}, \"\n",
    "            f\"AGE: {row['AGE']}, DIS: {row['DIS']}, RAD: {row['RAD']}, \"\n",
    "            f\"TAX: {row['TAX']}, PTRATIO: {row['PTRATIO']}, B: {row['B']}, \"\n",
    "            f\"LSTAT: {row['LSTAT']}\"\n",
    "        )\n",
    "        ########################################################################\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: create the output string from part of the values in 'row'.\n",
    "        # This string should contain the value in\n",
    "        # the last column without any additional text so we can easily convert\n",
    "        # the trained model's output to floating point values later\n",
    "        output_string = str(row['MEDV'])\n",
    "        ########################################################################\n",
    "\n",
    "        formatted_data.append((input_string, output_string))\n",
    "\n",
    "    return pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UQ6rbimj4oh"
   },
   "source": [
    "3. Split the data into training, validation, and test sets\n",
    "\n",
    "It's essential to divide our data into three separate sets: training, validation, and test. Let's understand why this is crucial:\n",
    "\n",
    "- Training Data:  This is the largest portion of our data, used to directly train the model's parameters.\n",
    "- Validation Data: Held separate from the training data, this set is used to fine-tune the model's hyperparameters (like learning rate, batch size, epochs) and get an early sense of its performance on unseen data.\n",
    "- Test Data: The most important subset! It's kept hidden from the model during training and validation and used only at the very end to provide an unbiased evaluation of the final model's performance.\n",
    "\n",
    "To efficiently feed our data to the T5 model during training, we'll create a custom dataset class and a data collate function. They handle the extraction and tokenization of our text data and organizes it into a format readily consumable by the PyTorch DataLoader.\n",
    "\n",
    "**Key Benefits of Defining a Custom Dataset Class and a Data Collate Function**\n",
    "- Organized Data Loading:  Simplifies the process of accessing and preparing data batches during training. Especially when the data may be coming in various format (e.g. dictionaries, lists, dataframes, etc.).\n",
    "- On-the-Fly Tokenization:  Performs tokenization (more on this in the next section) and sequence length padding efficiently when a data sample is requested.\n",
    "- Integration with DataLoader:  Works seamlessly with PyTorch's DataLoader for data multi-processing and data shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tDt9e509WDlH"
   },
   "outputs": [],
   "source": [
    "class OurDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, at_index: int) -> dict:\n",
    "        item_at_index = dict.fromkeys(['text', 'label'])\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Get the input string at the given index out of the Pandas\n",
    "        # DataFrame and add it into a dictionary\n",
    "        # store this input string with the key 'text'\n",
    "        item_at_index['text'] = self.data.iloc[at_index, 0]\n",
    "        ########################################################################\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Get the output string at the given index out of the Pandas\n",
    "        # DataFrame and add it into a dictionary\n",
    "        # store this output string with the key 'label'\n",
    "        item_at_index['label'] = self.data.iloc[at_index, 1]\n",
    "        ########################################################################\n",
    "\n",
    "        # Return the item dictionary to the dataloader for batching\n",
    "        return item_at_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frHr6D4Ij2Sz",
    "outputId": "728559e0-2d55-4c31-a4e5-ec479a2e8aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 404\n",
      "First train datapoint\n",
      " {'text': 'CRIM: 15.0234, ZN: 0.0, INDUS: 18.1, CHAS: 0.0, NOX: 0.614, RM: 5.304, AGE: 97.3, DIS: 2.1007, RAD: 24.0, TAX: 666.0, PTRATIO: 20.2, B: 349.48, LSTAT: 24.91', 'label': '12.0'}\n",
      "Validation data size: 51\n",
      "First val datapoint\n",
      " {'text': 'CRIM: 0.00632, ZN: 18.0, INDUS: 2.31, CHAS: 0.0, NOX: 0.538, RM: 6.575, AGE: 65.2, DIS: 4.09, RAD: 1.0, TAX: 296.0, PTRATIO: 15.3, B: 396.9, LSTAT: 4.98', 'label': '24.0'}\n",
      "Test data size: 51\n",
      "First test datapoint\n",
      " {'text': 'CRIM: 0.13914, ZN: 0.0, INDUS: 4.05, CHAS: 0.0, NOX: 0.51, RM: 5.572, AGE: 88.5, DIS: 2.5961, RAD: 5.0, TAX: 296.0, PTRATIO: 16.6, B: 396.9, LSTAT: 14.69', 'label': '23.1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split and process each partition of the dataset individually\n",
    "# Train data is used to train model's parameters\n",
    "# Val data is used pick model's hyperparameters\n",
    "# Test data is used to evaluate the model's performance\n",
    "train_data, val_test_data = train_test_split(data, test_size=0.2, random_state=42)  # Split into train and temp sets\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)  # Split temp into val and test sets\n",
    "\n",
    "# Apply the reformatting function\n",
    "train_data = reformat_dataset(train_data)\n",
    "val_data = reformat_dataset(val_data)\n",
    "test_data = reformat_dataset(test_data)\n",
    "\n",
    "# Create our custom datasets\n",
    "train_data = OurDataset(train_data)\n",
    "val_data = OurDataset(val_data)\n",
    "test_data = OurDataset(test_data)\n",
    "\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"First train datapoint\\n\", train_data[0])\n",
    "print(\"Validation data size:\", len(val_data))\n",
    "print(\"First val datapoint\\n\", val_data[0])\n",
    "print(\"Test data size:\", len(test_data))\n",
    "print(\"First test datapoint\\n\", test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254,
     "referenced_widgets": [
      "73203d2aa7a44fc684534fa985d1a15d",
      "b2dfe6ab52d54bb9a2359c106f2bb430",
      "edc81bc49b684b59ba44f94b8c6acf72",
      "dce4d5635b2849aaae38be69c9ccd59f",
      "4ae56dffde6041e190d94a54a068d320",
      "14bce80ea19c49d7ada1a19c3c597bd2",
      "5bbd8f2b54694a019ae4b90331fd0173",
      "b5e6b597947544b09e46c96d26b933d3",
      "b2ae8742877a4fd78faf7a3864e4d34d",
      "62e7e6c3d16645d581403db1d7bb817e",
      "a9a8fa50eff542ccb00daba6cda0df4d",
      "7415bd0d72364f92b60b9ac68a254746",
      "ce1dfcb10e444f7eac5ef554137baeaa",
      "e16b7041e82343c08b0d41313d2a5531",
      "e9aad2f173b44d0b93f8ab14e27956ef",
      "73e32194157a452d945ee0c30da2fcb1",
      "ddb86aa19cab4c599df8165ca9e2a03a",
      "0be7666845884c30a42359b1d99f97e5",
      "857b63c4f0f347ae8ecde965b945c7da",
      "5035ae64dbef4ea59cb299c357f8cd62",
      "342a1601026d4695a7c0e632e07261f9",
      "02f12a69e48f4642b4b2e0344f76e959",
      "2eb64c38c5fc4256b07657d2abb7f137",
      "c5156e5e50474133bf56410f3cd1cea9",
      "e2975901da744ee894a101511f21c39b",
      "97a3e5f1f22e4d69adeeb8328f3cd60f",
      "c89484a7448a478c90687fc856fab969",
      "e0b5ecfa7f83430da73fbb86504997e7",
      "6303e0595e164a62802df97bf4111933",
      "8ae4314e7fb34d07b0d39b736e7af2f0",
      "9f99b487163f47a78db3a9b26f07ea20",
      "c95066f590df481e9708cb09876c4f0b",
      "f8936a9ca58b4989836a9b57259c3991"
     ]
    },
    "id": "m12KcsAyxw5o",
    "outputId": "0e73e9e1-dfc7-4dc3-d9fe-f47d72c546c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2ec6846da04479a95384f96a4a31cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sudha\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sudha\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704f5f006a5a4c699684455af89f533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc05b984eba43fdb0b10f88ea249b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")  # Load the tokenizer for the 'collate_fn' context\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Tokenize datapoints in batch, we do padding depending on longest sequence\n",
    "    # in the batch\n",
    "    text = tokenizer([datapoint['text'] for datapoint in batch], padding=True, return_tensors='pt')\n",
    "    labels = tokenizer([datapoint['label'] for datapoint in batch], padding=True, return_tensors='pt')\n",
    "    return {'input_ids': text['input_ids'], 'attention_mask': text['attention_mask'], 'labels': labels['input_ids']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfyeiAq-kDMP"
   },
   "source": [
    "# Part 2: Model Fine-tuning\n",
    "\n",
    "1. Load the pre-trained T5-small model and tokenizer\n",
    "\n",
    "In this project, we'll be working with the \"T5-small\" model, a lightweight but powerful Transformer-based language model developed by Google.  Let's see what makes T5 ([Documentation](https://huggingface.co/docs/transformers/en/model_doc/t5)) special and why it's well-suited for our task.\n",
    "\n",
    "**T5 Architecture and Training: A Versatile Language Model**\n",
    "\n",
    "- Encoder-Decoder Structure:  As introduced in [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf), T5 consists of two main components: an encoder that processes the input text into a context vector and a decoder that autoregressively generates the output text based on the context vector and generated texts.\n",
    "- Text-to-Text Framework: What sets T5 apart is its pre-training approach. It was pre-trained on a massive dataset of text-to-text tasks, where it learns various NLP tasks (translation, summarization, question answering) in a unified text-to-text format.\n",
    "    - C4 Dataset:  T5 is pre-trained on the [Colossal Clean Crawled Corpus (C4)](https://huggingface.co/datasets/allenai/c4), a vast dataset of text and code scraped from the entier internet. This extensive and diverse training data makes T5 remarkably versatile and capable of adapting to various NLP tasks.\n",
    "\n",
    "**The Role of the Tokenizer**\n",
    "\n",
    "- Bridging the Gap Between Text and Vectors:  Deep learning models operate on numerical vectors, not raw text. The tokenizer acts as a translator between the two.\n",
    "- Vocabulary and Tokenization:  It has a predefined vocabulary (a mapping between words or subwords and numerical IDs). The tokenizer splits the input text into individual tokens (words or subwords) and converts them into their corresponding numerical IDs. The model can then convert these IDs into the corresponding vector using its trainable look-up table.\n",
    "\n",
    "You may wonder: how can these vectors stand in place of words? The magic happened when the model was pre-trained on the internet, it learns to map semantically related words (typically used in similar contexts) to similar vectors, while words that are unrelated are mapped to othorgonal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01gdMy0jkBCd",
    "outputId": "629721e5-de18-44ae-9eb5-c41647b9d19b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5537a0bcc3d3410db270b4d24ed03134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be62becd94554f28b8e284c0594409de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d506ace2a5d4a6b8f9a9d5b0d0fbd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 60,506,624 trainable parameters.\n",
      "Tokenizer has a vocabulary of 32100 tokens.\n",
      "\n",
      "Tokens of the sentence \"I wish birds can perform the blues when Spring comes!\" are:\n",
      "['▁I', '▁wish', '▁birds', '▁can', '▁perform', '▁the', '▁blue', 's', '▁when', '▁Spring', '▁comes', '!']\n",
      "\n",
      "Tokens of the sentence \"0.123, 903, 100, -43.32\" are:\n",
      "['▁0.', '123', ',', '▁90', '3,', '▁100', ',', '▁', '-', '43', '.', '32']\n",
      "\n",
      "Vocab IDs of the sentence \"I wish birds can perform the blues when Spring comes!\" are:\n",
      "[27, 1663, 6331, 54, 1912, 8, 1692, 7, 116, 4328, 639, 55, 1]\n",
      "\n",
      "Vocab IDs of the sentence \"0.123, 903, 100, -43.32\" are:\n",
      "[4097, 14574, 6, 2777, 6355, 910, 6, 3, 18, 4906, 5, 2668, 1]\n",
      "\n",
      "Cosine similarity score between \"cat\" and \"kitten\": 0.443185955286026\n",
      "\n",
      "Cosine Similarity score between \"cat\" and \"high\": 0.0012265145778656006\n",
      "\n",
      "Cosine Similarity score between \"high\" and \"low\": 0.6634555459022522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")  # Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "model.to(device)  # Move the model to the device\n",
    "model_p_count = sum([p.numel() for p in filter(lambda p: p.requires_grad, model.parameters())])\n",
    "\n",
    "print(f\"Model has {model_p_count:,} trainable parameters.\")  # Print the number of trainable parameters in T5\n",
    "print(f\"Tokenizer has a vocabulary of {len(tokenizer.get_vocab())} tokens.\") # Print the tokenizer's states\n",
    "print()\n",
    "\n",
    "# Let's see how to tokenizer works on example strings\n",
    "# You may notice that a token is approximately a word (but not really),\n",
    "# this is so that the model learns the compositionality of the human language\n",
    "s1 = \"I wish birds can perform the blues when Spring comes!\"\n",
    "s2 = \"0.123, 903, 100, -43.32\"\n",
    "print(f\"Tokens of the sentence \\\"{s1}\\\" are:\\n{tokenizer.tokenize(s1)}\")\n",
    "print()\n",
    "print(f\"Tokens of the sentence \\\"{s2}\\\" are:\\n{tokenizer.tokenize(s2)}\")\n",
    "print()\n",
    "\n",
    "# Let's see the IDs those tokens are associated with\n",
    "# You may notice there is an extra token ID 1 at the end of the 2 sentences,\n",
    "# that is the special end-of-sentence token that allows the model to learn\n",
    "# when to stop prolonging the sentence\n",
    "print(f\"Vocab IDs of the sentence \\\"{s1}\\\" are:\\n{tokenizer(s1)['input_ids']}\")\n",
    "print()\n",
    "print(f\"Vocab IDs of the sentence \\\"{s2}\\\" are:\\n{tokenizer(s2)['input_ids']}\")\n",
    "print()\n",
    "\n",
    "# Let's check the embedding of two similar words versus two disimilar words\n",
    "# We know these words are to be tokenized into single tokens and we ignore the\n",
    "# end-of-sentence token\n",
    "word1 = \"cat\"\n",
    "word2 = \"kitten\"\n",
    "word3 = \"high\"\n",
    "word4 = \"low\"\n",
    "embedded_vector1 = model.get_input_embeddings()(torch.tensor([tokenizer(word1)['input_ids'][0]]))\n",
    "embedded_vector2 = model.get_input_embeddings()(torch.tensor([tokenizer(word2)['input_ids'][0]]))\n",
    "embedded_vector3 = model.get_input_embeddings()(torch.tensor([tokenizer(word3)['input_ids'][0]]))\n",
    "embedded_vector4 = model.get_input_embeddings()(torch.tensor([tokenizer(word4)['input_ids'][0]]))\n",
    "# The cosine similarity will return a value between -1 and 1:\n",
    "# a value closer to 1 indicates very aligned,\n",
    "# closer to -1 means very disaligned,\n",
    "# and closer to 0 means unrelated words\n",
    "print(f\"Cosine similarity score between \"\n",
    "      f\"\\\"{word1}\\\" and \\\"{word2}\\\": {torch.nn.functional.cosine_similarity(embedded_vector1, embedded_vector2).item()}\")\n",
    "print()\n",
    "print(f\"Cosine Similarity score between \"\n",
    "      f\"\\\"{word1}\\\" and \\\"{word3}\\\": {torch.nn.functional.cosine_similarity(embedded_vector1, embedded_vector3).item()}\")\n",
    "print()\n",
    "print(f\"Cosine Similarity score between \"\n",
    "      f\"\\\"{word3}\\\" and \\\"{word4}\\\": {torch.nn.functional.cosine_similarity(embedded_vector3, embedded_vector4).item()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aieBjlOTkLGF"
   },
   "source": [
    "2. Define training hyperparameters\n",
    "\n",
    "Now that we've loaded our pre-trained T5 model, let's dive into the process of fine-tuning it on our dataset. A crucial part of this process involves understanding and setting appropriate hyperparameters.\n",
    "\n",
    "**Hyperparameter Deep Dive: Navigating the Training Landscape**\n",
    "\n",
    "Hyperparameters are like the control knobs of our training process. They influence how the model learns from the data.  Let's explore three essential hyperparameters:\n",
    "\n",
    "- Learning Rate: This hyperparameter determines how big of a step we update the model's parameters in the direction of minimizing the model's loss during each training iteration.\n",
    "- Smaller Learning Rate (e.g., 1e-5): The model learns more slowly but might find a more precise solution.\n",
    "- Larger Learning Rate (e.g., 1e-3): Faster learning, but the model might overshoot the optimal solution and not converge well.\n",
    "- Batch Size: Instead of feeding the entire training dataset to the model at once, we divide it into smaller groups called batches.\n",
    "- Smaller Batch Size (e.g., 8, 16): Requires less memory, but updates to the model's parameters can be noisy.\n",
    "- Larger Batch Size (e.g., 32, 64): More computationally efficient, smoother updates, but might require more memory.\n",
    "- Epochs: An epoch represents one complete pass through the entire training dataset.\n",
    "- Too Few Epochs: The model might underfit the data, meaning it hasn't learned the patterns well enough.\n",
    "- Too Many Epochs: The model might overfit the data, memorizing the training examples but performing poorly on unseen data.\n",
    "\n",
    "Finding the optimal balance for these hyperparameters often involves experimentation and observing the model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "R61j0nPwkJOO"
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-5  # Change this as you like\n",
    "batch_size = 16  # Change this as you like\n",
    "epochs = 30  # Change this as you like, you might want to train much longer to get adequate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChDBXDQykRc9"
   },
   "source": [
    "3. Define training loop\n",
    "\n",
    "Now that we have our data, model, and hyperparameters set, it's time to bring them all together in the training loop. This loop is where the magic happens - it's where our T5 model learns from the data to become proficient in housing price prediction.\n",
    "\n",
    "**Training Phase**\n",
    "1. Set the model to training mode\n",
    "2. Clear any previously calculated gradients\n",
    "3. Extract data from dataloader and move them to the correct device\n",
    "4. Forward Pass: Calculate the model's predictions\n",
    "5. Calculate how far off the predictions are\n",
    "6. Backward Pass: Calculate gradients for each parameter\n",
    "7. Update Model Parameters:  Adjust model parameters to minimize the loss\n",
    "\n",
    "**Validation Phase**\n",
    "1. After each epoch, we evaluate the model's progress on the validation set\n",
    "2. Set the model to evaluation mode (no parameter updates)\n",
    "3. Disable gradient calculation to save memory\n",
    "4. Similar to the training loop, but we aim to calculate the matching between model's predictions and ground-truth labels without any parameter adjustments\n",
    "\n",
    "Normally, evaluating the next-token prediction capability of a language model requires the [BLEU and ROUGE metrics](https://medium.com/@raniahossam/cracking-the-code-of-text-evaluation-unveiling-the-magic-of-rouge-metrics-bb0c687f479f). However, in our case, this metric would not be appropriate as we want the error between the model's numerical values versus the ground-truth price.\n",
    "\n",
    "For example, the model's prediction of \"cat.2\" versus a ground-truth label of \"245.2\" should be a 0 accuracy score in our case instead of a 0.5 score that the ROUGE metric would assign. Instead, we must convert the model's output and ground-truth label into numerical values, then using an appropriate regression metric - [R-squared](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html) - to evaluate the model's performance (it is highly recommended that you understand how this metric behaves for certain model's behaviors so you can answer questions in the final report).\n",
    "\n",
    "Hint: If your implementation is correct so far, you should expect the model to fail to output (only) floating-point numbers at first, which is considered negative infinity validation score for obvious reasons, and only output numbers as the training progresses (but very lousy numbers), which allows for a non-infinity but moderately large negative validation score. As the model gets better at predicting house prices, you should see the validation score becomes positive and converges toward 1.\n",
    "\n",
    "**Checkpointing: Model saving and loading**\n",
    "\n",
    "Training LLMs can take a long time, sometimes hours or days! Checkpointing helps us to:\n",
    "\n",
    "- Save Our Progress:  Regularly saving checkpoints allows us to resume training from the last saved point if an interruption occurs (e.g., power outage, system crash).\n",
    "- Capture the Best Model: By saving the model with the highest validation score so far, we can keep track of our best-performing model during training while avoiding training degradation.\n",
    "\n",
    "**IMPORTANT NOTE** If you left your Colab environment unattended for some time, it may delete your saved files. I recommend that you regularly backup your files by downloading them onto your computer's drive once in a while, and reupload them to Colab if your files are deleted by Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LmmExSfixzvn"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = './trained_model.pth'\n",
    "DATALOADER_PATH = './dataloaders.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "VxNqv9JeV8GN"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_dataloader, val_dataloader, epochs, best_accuracy):\n",
    "    \"\"\"Trains the model and evaluates on the validation set. Returned trained model and loss/validation progress.\"\"\"\n",
    "    loss_progress = []\n",
    "    val_progress = []\n",
    "    for epoch in range(start_epoch - 1, epochs):\n",
    "        model.train()  # Trigger training mode (enable gradient tracking)\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}', leave=False)\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            # Get necessary arguments out of 'batch', feed them to model, to obtain the model's output\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            model_outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = model_outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})  # Update progress bar\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        loss_progress.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Avg. Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # Trigger testing mode (disable gradient tracking)\n",
    "        total_val_accuracy = 0\n",
    "        progress_bar = tqdm(val_dataloader, desc=f'Epoch {epoch + 1}', leave=False)\n",
    "        for batch in progress_bar:\n",
    "            # Get necessary arguments out of 'batch', feed them to model, to obtain the model's output\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Call HuggingFace's special 'generate' method to do autoregressive sampling of next tokens\n",
    "            # Note that this method is not differentiable/trainable as it performs discrete operations\n",
    "            # such as token sampling and sequence path searching. Documentation here:\n",
    "            # https://huggingface.co/docs/transformers/en/main_classes/text_generation\n",
    "            generate_outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=10)\n",
    "\n",
    "            decoded_preds = tokenizer.batch_decode(generate_outputs, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # Compute the R-squared score between the predicted strings and label strings\n",
    "            # We turn these strings into float for the R-squared computation\n",
    "            # but if model's output cannot be converted to a float,\n",
    "            # we can consider that an infinite error (accuracy = -infinity)\n",
    "            try:\n",
    "              predicted_values = [float(pred) for pred in decoded_preds]\n",
    "              actual_values = [float(label) for label in decoded_labels]\n",
    "              val_score = sklearn.metrics.r2_score(predicted_values, actual_values)\n",
    "            except ValueError:\n",
    "              val_score = float('-inf')\n",
    "            total_val_accuracy += val_score\n",
    "            progress_bar.set_postfix({'accuracy': val_score})  # Update progress bar\n",
    "\n",
    "        val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "        val_progress.append(val_accuracy)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Avg. Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Best-so-far Model Checkpointing\n",
    "        if val_accuracy >= best_accuracy:\n",
    "            print(f\"New latest and best accuracy! Saving model checkpoint to {CHECKPOINT_PATH}\")\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "                'accuracy': best_accuracy,\n",
    "            }, CHECKPOINT_PATH)\n",
    "\n",
    "    return model, loss_progress, val_progress  # Return the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i5nRz6z1kPfT",
    "outputId": "4b2bff75-5285-4d98-e306-2f546096bf67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_12832\\1805009257.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH)\n",
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_12832\\1805009257.py:10: UserWarning: \n",
      "\n",
      "Found model checkpoint at ./trained_model.pth.\n",
      "Loaded model and optimizer from epoch 79.\n",
      "  warnings.warn(f\"\\n\\nFound model checkpoint at {CHECKPOINT_PATH}.\\n\"\n",
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_12832\\1805009257.py:12: UserWarning: \n",
      "\n",
      "Validation accuracy: 0.4137520431344386\n",
      "  warnings.warn(f\"\\n\\nValidation accuracy: {checkpoint['accuracy']}\")\n",
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_12832\\1805009257.py:13: UserWarning: \n",
      "\n",
      "Loss: 1.0595055726858287\n",
      "  warnings.warn(f\"\\n\\nLoss: {checkpoint['loss']}\")\n",
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_12832\\1805009257.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(DATALOADER_PATH)\n",
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_12832\\1805009257.py:25: UserWarning: \n",
      "\n",
      "Found saved dataloaders at ./dataloaders.pth.\n",
      "Loaded dataloaders (specifying a previous data order and data slit).\n",
      "  warnings.warn(f\"\\n\\nFound saved dataloaders at {DATALOADER_PATH}.\\n\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  # You can choose a different optimizer if you wish\n",
    "\n",
    "# Resume a previous training session if applicable\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_accuracy = checkpoint['accuracy']\n",
    "    warnings.warn(f\"\\n\\nFound model checkpoint at {CHECKPOINT_PATH}.\\n\"\n",
    "                  f\"Loaded model and optimizer from epoch {checkpoint['epoch']}.\")\n",
    "    warnings.warn(f\"\\n\\nValidation accuracy: {checkpoint['accuracy']}\")\n",
    "    warnings.warn(f\"\\n\\nLoss: {checkpoint['loss']}\")\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    best_accuracy = float('-inf')\n",
    "    warnings.warn(\"\\n\\nNo model checkpoint found.\\nStarting from scratch.\")\n",
    "\n",
    "# IMPORTANT: Save/load the dataloaders to ensure same data order and data split across different runtimes\n",
    "if os.path.exists(DATALOADER_PATH):\n",
    "    checkpoint = torch.load(DATALOADER_PATH)\n",
    "    train_dataloader = checkpoint['train_dataloader']\n",
    "    val_dataloader = checkpoint['val_dataloader']\n",
    "    test_dataloader = checkpoint['test_dataloader']\n",
    "    warnings.warn(f\"\\n\\nFound saved dataloaders at {DATALOADER_PATH}.\\n\"\n",
    "                  f\"Loaded dataloaders (specifying a previous data order and data slit).\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=len(val_data), shuffle=False, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False, collate_fn=collate_fn)\n",
    "    torch.save({\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'val_dataloader': val_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "    }, DATALOADER_PATH)\n",
    "    warnings.warn(\"\\n\\nStarting with new data order and data slit.\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trained_model, loss_progress, val_progress = train_model(model, optimizer, train_dataloader, val_dataloader, epochs, best_accuracy)\n",
    "\n",
    "# Plot the training loss and validation progression on the same graph over epochs\n",
    "plt.plot(loss_progress, label='Training Loss')\n",
    "plt.plot(val_progress, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss/accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTpNICjlIaAs",
    "outputId": "9ecfa838-35f3-479e-e3bb-e0c98ac6c738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# Get the model's R-squared score on the test data, this step should be quite\n",
    "# similar to what we have for the validation phase above\n",
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False, collate_fn=collate_fn)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in test_dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    generate_outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=10)\n",
    "    decoded_preds = tokenizer.batch_decode(generate_outputs, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    try:\n",
    "      predicted_values = [float(pred) for pred in decoded_preds]\n",
    "      actual_values = [float(label) for label in decoded_labels]\n",
    "      test_score = sklearn.metrics.r2_score(predicted_values, actual_values)\n",
    "    except ValueError:\n",
    "      test_score = float('-inf')\n",
    "print(f\"Test Accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsU0eMzBX-nc"
   },
   "source": [
    "# Part 3: Comparison Study\n",
    "Let's look at alternative models commonly used in ML ([linear regression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html), [decision tree learning](https://scikit-learn.org/1.5/modules/tree.html), [random forest, XG boost](https://scikit-learn.org/1.5/modules/ensemble.html)) and have proven to be very powerful in modeling large datasets. You might have already learned some of them in this and other AI/ML-topic courses. SKLearn provides a fast and convenient pipeline for us to load up different ML models and train/cross-validate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4xDP6PiYUoC",
    "outputId": "8124cc14-a7a1-4dbe-e44f-f5666299071e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "Train Accuracy: 0.7493\n",
      "Validation Accuracy: 0.3533\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.2630\n",
      "\n",
      "RandomForestRegressor:\n",
      "Train Accuracy: 0.9817\n",
      "Validation Accuracy: 0.6237\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "Train Accuracy: 0.9788\n",
      "Validation Accuracy: 0.6728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_other_ML_models(X, y):\n",
    "    for model in [LinearRegression(),\n",
    "                  DecisionTreeRegressor(),\n",
    "                  RandomForestRegressor(),\n",
    "                  GradientBoostingRegressor()]:\n",
    "        scores = cross_validate(model, X, y, cv=5, return_train_score=True)\n",
    "        # Average over the different fold-divisions and print results\n",
    "        print(f\"{model.__class__.__name__}:\")\n",
    "        print(f\"Train Accuracy: {scores['train_score'].mean():.4f}\")\n",
    "        print(f\"Validation Accuracy: {scores['test_score'].mean():.4f}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# Normalize the data for other ML models\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64'])\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numeric_features.drop(columns=['MEDV']))\n",
    "\n",
    "train_other_ML_models(\n",
    "    X=scaled_features,\n",
    "    y=numeric_features['MEDV']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Final Report and Student's Reflection\n",
    "\n",
    "From your experiments in the previous parts, answer each of the following 14 questions (200 words or less for each question). Please type your answer below each of the questions (you can edit the text cell by double click on a word in the cell):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzqsJJnFY2k7"
   },
   "source": [
    "### 1. Report ALL the hyperparameters you've used in training the T5 model on the Boston house price prediction task (e.g. what is the train-val-test split percentage? how many epochs did you train the model? etc.).\n",
    "\n",
    "The hyperparameters used are:\n",
    "\n",
    "    1) Learning Rate (value=1e-4): The learning rate controls how much the model's weights are adjusted with each update during training. A smaller value like 1e-4 means the model will learn more slowly, making smaller updates to its parameters and potentially leading to more stable training and finer tuning.\n",
    "\n",
    "    2) Batch Size (value=32): The batch size refers to the number of training examples used in one forward/backward pass of the model. A batch size of 32 was chosen, which is a common choice to balance memory usage and computational efficiency. Smaller batches lead to noisier gradients, while larger batches give more stable updates but use more memory.\n",
    "\n",
    "    3) Epochs (value=100): An epoch is one full pass through the entire training dataset. 100 epochs means the model will process the entire dataset 100 times, allowing it to learn over multiple iterations. Training for too few epochs can result in underfitting, while too many may lead to overfitting. The graph shows that 25-30 epochs is the optimal no.of epochs.\n",
    "\n",
    "    4) Train-Val-Test Split (70%-15%-15%): This is the proportion of the dataset used for training, validation, and testing. 70% for training, 15% for validation, and 15% for testing ensure that there is enough data to both train the model and evaluate its performance on unseen data, helping to prevent overfitting.\n",
    "\n",
    "    5) Optimizer (AdamW): The optimizer controls how the model's weights are updated during training. AdamW is an adaptive optimizer that adjusts the learning rate based on the gradient, and the \"W\" refers to weight decay, which helps reduce overfitting by penalizing large weights.\n",
    "    \n",
    "    6) Loss Function (Cross-Entropy): The loss function measures how far the model's predictions are from the true labels. In this case, cross-entropy loss was used for language models but adjusted to suit the regression task, where the goal was to predict numerical values (house prices) rather than categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Did you try different values for each hyperparameter? What are they? Which value(s) you have found to be the best at helping the model reach higher test accuracy?\n",
    "\n",
    "Yes, I experimented with different values for several hyperparameters. Initially, I tested different values for the number of epochs, and I found that training for 30 epochs resulted in the highest test accuracy, improving it to 0.7. Afterward, I explored adjusting the batch size and learning rate. Specifically, I tested a batch size of 16 and learning rates of 1e-5 and 5e-5. However, these changes did not significantly impact the test accuracy, which remained stable. Based on these experiments, I concluded that 30 epochs was the optimal value for epochs. For both learning rate (1e-4) and batch size (32), the initial values were already well-suited for achieving good performance. This tuning approach led to a test accuracy of 0.7, a substantial improvement from the initial value of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Report the final model training loss and its accuracy on the held-out test data.\n",
    "\n",
    "Final Values after my optimizations:\n",
    "\n",
    "    1) Training Loss: 1.0595055726858287\n",
    "    \n",
    "    2) Validation accuracy: 0.4137520431344386\n",
    "\n",
    "    3) Test Accuracy:0.7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the model's test accuracy (R-squared score) if it always answer with the average value over the housing prices in the dataset regardless of the input features? Did your trained model do better than that score?\n",
    "\n",
    "As we can see from R^2 formula, if model always answers with average value, SSR and SSE will cancel each other out, making that fraction value 1. When subtracted from 1, the R^2 will become 0. My trained model did better than that initially, providing an R^2 of around 0.5 first. When hyperparameters were tuned, R^2 grew to 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. There is no correct answer to this question. From your results, do you think it understand the human housing market? to what degree does it do/don't? how do you think the modality difference (the strict numerical pricing values versus the loosely defined textual price format) impact the learning of our language model? did you notice highly discontinuous and erratic jumps in the model's validation score over the training epochs (e.g. it goes from -inf to -0.5 to -155.3 to 0.33, etc. in immediate steps)? why?\n",
    "##### Hint: pay attention to how the model's inner workings are numerical computations (matrix multiplications and additions) but it must work with and adapt to discrete tokens at its input and output endpoints.\n",
    "\n",
    "The model’s performance on predicting housing prices suggests that while it can learn some patterns and relationships between features, it does not fully \"understand\" the human housing market in the way a human expert or even simpler machine learning models might. The model is essentially learning a mapping from textual input to a numerical output based on patterns in the data. However, the lack of a true understanding of the domain (such as factors affecting housing prices, economic dynamics, etc.) limits its ability to generalize well on real-world, unseen data.\n",
    "\n",
    "The model’s predictions are influenced by the quality of the data it is trained on. If the training data doesn’t capture the full complexity of the housing market or is noisy, this will reflect in the model’s output. For instance, while the model may learn associations (e.g., “large square footage” correlates with higher prices), it doesn’t understand why or how certain factors interact in the real world, such as the effects of interest rates, location trends, or supply-demand dynamics.\n",
    "\n",
    "The shift from strict numerical pricing values (as seen in traditional regression models) to loosely defined textual price formats can create challenges for the language model. In a numerical pricing format, the model is predicting a continuous value, while in a textual format, the model predicts tokenized representations of text, which can then be decoded into a number. This discrepancy between the model's expected output (text tokens) and the desired output (numerical values) introduces an extra layer of complexity.\n",
    "\n",
    "This mode mismatch could result in the model initially struggling to predict well-formatted numerical outputs, especially early on in training. For example, early model predictions may be poorly structured or lack precision because the model is trying to map continuous prices into text representations.\n",
    "\n",
    "I did see highly erratic jumps in the validation score during training, especially since this is a large language model. This happens mainly due to discrete token outputs - The model operates in discrete token space, but internally, its computations are continuous (matrix multiplications, etc.). This mismatch causes instability when predicting a continuous range of values. Sometimes the model may generate wildly different outputs from one epoch to the next, even if the internal updates seem small, which can lead to large swings in validation scores (e.g., from -inf to positive values in just a few steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What part of the T5's pre-trained internet data you think might have helped its performance on our Boston house price prediction task?\n",
    "\n",
    "T5 (Text-to-Text Transfer Transformer) was pre-trained on a large corpus of text data from the internet, which likely included diverse sources such as news articles, books, encyclopedias, websites, and forums. While T5 was not specifically trained on structured numerical data like the Boston housing prices, I think the aspect of the pre-trained model's data and architecture could have contributed to its performance on this task. T5's pre-training exposed it to vast amounts of natural language data. This helped the model develop a strong understanding of how language works, including interpreting various descriptions, summaries, and numbers expressed in text. For instance, the model can interpret features like \"square footage\" or \"location\" as potentially related to a house's price, even though it was not specifically trained for house pricing. The model could leverage this linguistic understanding to associate words describing housing characteristics with the appropriate numeric value (price). It's ability to understand language, generalize relationships, and learn from diverse contexts likely helped it perform reasonably well on the Boston housing price prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What part of the T5's pre-trained internet data you think might have hurt its performance on our Boston house price prediction task?\n",
    "\n",
    "While T5's pre-trained data provided it with numerous advantages, certain aspects of its pre-training corpus may have negatively impacted its performance on the Boston housing price prediction task. Mainly, while T5 was trained on diverse text, it was not explicitly trained to handle structured, numerical data. Its primary function is processing and generating text, not performing precise numerical calculations or regression tasks. Therefore, the model might struggle to handle precise numerical reasoning when mapping textual features (like \"5 bedrooms\" or \"1,500 sq ft\") to specific numeric outputs (like housing prices). This could result in less accurate or inaccurate price predictions, as T5’s internal mechanisms for interpreting numbers may not be as refined as those of models explicitly designed for numerical prediction.\n",
    "\n",
    "Also, T5 processes text in discrete tokens, which means that it represents numbers (such as housing prices) as tokens in a text sequence. This can lead to problems when working with highly specific numerical data, like house prices, where continuous values are critical. In this case, T5 might treat the prices as discrete textual entities rather than continuous variables, causing discontinuities or rounding errors when making predictions. This issue likely contributed to the erratic jumps in validation scores that were observed during training, where the model’s output would fluctuate unpredictably between values.\n",
    "\n",
    "Since T5 is a text-to-text model, its training was focused on sequence generation, which involves producing sequences of text based on input text. This might not align well with the needs of a regression task, where the goal is to produce a single, continuous value (house price). The model’s tendency to generate sequences of text may have led it to misinterpret the task by generating a sequence of predictions, rather than focusing on producing an exact numerical output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Did you observe the model overfitting (complete memorization of) our training data? how do you know it did/didn't?\n",
    "\n",
    "Overfitting occurs when a model learns to perform exceptionally well on the training data but fails to generalize to new, unseen data, essentially memorizing the training set rather than learning underlying patterns. In the case that the model's training accuracy was quite high while the validation accuracy (or R-squared score) remained lower, or it fluctuated unpredictably,it would suggest that the model was memorizing the training data rather than learning generalizable patterns. However, after tuning hyperparameters, the model showed relatively consistent improvements in validation accuracy throughout training. The model was trained for 30 epochs, which were selected based on optimal performance as seen in the validation accuracy graph. The fact that the model's performance on the validation data remained steady and the best epoch count was 30 indicates that we avoided excessive training that could have caused overfitting. The best indicator for overfitting is how well the model performs on the held-out test data. In our case, the test accuracy (R-squared score) is 0.7, which indicates that the model was able to generalize beyond the training data to some extent. If the model had overfitted, we would expect a much lower test performance, as the model would have memorized the training data and failed to adapt to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 9. What is the perfect number of training epochs that you would use to prevent your model from overfiting this task? why?\n",
    "#####   - If it is impossible to prevent overfitting, explain why you think so.\n",
    "#####   - If its trivial for the model to never overfit, explain why you think so.\n",
    "\n",
    "The perfect number of training epochs that I would use to prevent the model from overfiting this task is 30. The validation accuracy seemed to stabilize around this point, indicating that the model was able to learn useful patterns from the data without excessive memorization.The graph at the end also showed a stable and unwavering validation accuracy as well as training loss after the point of 30 epochs. Hence I think we should use 30 epochs in case there is a chance for overfitting due to possibility of training loss and validation accuracy curves diverging from each other as the number of training epochs increases. \n",
    "\n",
    "I tried to decrease overfitting as much as I could by doing that, sand the test accuracy did improve. So I think its not impossible to prevent overfitting in this case. Generally, in theory, it is always possible to reduce overfitting by tuning the model and using techniques like regularization, dropout, or data augmentation. \n",
    "\n",
    "In this case, since we were dealing with a very small dataset (which Boston housing data is relatively small for deep learning models) and a very powerful model like T5, overfitting would still be a risk. It would not be trivial for the model to never overfit, as overfitting is a common challenge in machine learning, especially when using powerful models on relatively small datasets. While early stopping helped in our case, it wasn’t guaranteed that overfitting wouldn’t occur. Hence it is not a trivial thing to create a model that never overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. How do you think you can improve the training algorithm or the dataset design or the model choice to do better at our Boston house price prediction task? what nuances you think is important in considering these choices?\n",
    "\n",
    "Improving the performance of a model like T5 on a regression task such as the Boston housing price prediction can be approached through various means, including adjustments to the training algorithm, dataset design, and model choice:\n",
    "\n",
    "    1) Learning Rate Scheduling such as learning rate warming or cosime annealing would help improve the training algorithm. Early Stopping and Regularization Techniques are also considerably helpful in improving the training algorithm in this case.\n",
    "\n",
    "    2) Data Augmentation/Feature Engineering, maybe even using Synthetic data generation, and Outlier Handling and better Data Preprocessing, I believe, would immensely help improve the dataset design and hence, subsequently, the model's performance too.\n",
    "    \n",
    "    3) Fine-tuning Other Pre-trained Models or a Hybrid Model Approach might be a better model choice rather than T5 since T5 is a powerful model for text generation tasks, and not exactly suited for regression tasks like predicting house prices. While the T5 model offers great potential, it may not be the best choice for a regression task with structured, tabular data like the Boston housing dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Report the results of your comparison study (between the T5 with each of the other ML models).\n",
    "\n",
    "For the T5 model after hyperparameter tuning,\n",
    "\n",
    "    1) Training Loss: 1.0595055726858287\n",
    "\n",
    "    2) Validation accuracy: 0.4137520431344386\n",
    "\n",
    "    3) Test Accuracy:0.7000\n",
    "\n",
    "For the Linear Regression model,\n",
    "\n",
    "    1) Train Accuracy: 0.7493\n",
    "\n",
    "    2) Validation Accuracy: 0.3533\n",
    "\n",
    "For the Decision Tree Regressor model,\n",
    "\n",
    "    1) Train Accuracy: 1.0000\n",
    "\n",
    "    2) Validation Accuracy: 0.2630\n",
    "\n",
    "For the Random Forest Regressor model,\n",
    "\n",
    "    1) Train Accuracy: 0.9817\n",
    "\n",
    "    2) Validation Accuracy: 0.6237\n",
    "\n",
    "For the Gradient Boosting Regressor model,\n",
    "\n",
    "    1) Train Accuracy: 0.9788\n",
    "    \n",
    "    2) Validation Accuracy: 0.6728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Why do you think each ML model do better/worse than the other? is your trained T5 achieving a better accuracy than some/all the other models? why do you think it might be doing better/worse than some/all of the other ML models?\n",
    "\n",
    "Each model's performance on the Boston house price prediction task reflects its strengths and weaknesses in dealing with structured numerical data, the dataset's complexity, and the training approach used.\n",
    "\n",
    "T5 Model:\n",
    "T5’s pretraining on a vast textual dataset helps it generalize to tasks requiring understanding of relationships between tokens. This might allow it to approximate the housing market relationships in a creative way. But, the tokenization of numerical values and reliance on textual output limit its precision for structured, continuous numerical regression tasks. It is inherently not optimized for tabular data.\n",
    "Performance: Achieved better test accuracy (R-squared = 0.7) than the baseline but underperformed compared to Gradient Boosting and Random Forest.\n",
    "\n",
    "Linear Regression:\n",
    "Works well on data with linear relationships, making it simple and interpretable. But, it struggles with non-linear data or complex interactions, which are common in housing markets. Underfitting is evident from the low validation R-squared.\n",
    "Performance: Inferior to other models due to its inability to model non-linearities.\n",
    "\n",
    "Decision Tree Regressor:\n",
    "Captures non-linear relationships and interactions effectively. But it overfits easily, especially on small datasets, as evidenced by its perfect train R-squared (1.0000) but poor validation R-squared.\n",
    "Performance: Performed the worst on validation, showing poor generalization.\n",
    "\n",
    "Random Forest Regressor:\n",
    "Combines the strengths of multiple decision trees, reduces overfitting, and captures non-linear relationships well. Requires tuning of hyperparameters like the number of trees and depth for optimal performance.\n",
    "Performance: Validation R-squared of 0.623, indicating solid performance without overfitting.\n",
    "\n",
    "Gradient Boosting Regressor:\n",
    "Learns residual errors iteratively, making it highly effective for capturing complex relationships. Robust to overfitting with proper regularization. Computationally intensive and sensitive to hyperparameter choices.\n",
    "Performance: Better validation R-squared of 0.6728, highlighting its effectiveness on structured regression tasks.\n",
    "\n",
    "The T5 model outperformed Linear Regression and Decision Tree Regressor, likely due to its ability to leverage pre-trained knowledge and avoid severe overfitting (as seen in Decision Trees). It underperformed compared to Random Forest and Gradient Boosting because those models are specifically designed for structured data regression and can better exploit numerical features and non-linear patterns in the data. The T5 model's performance highlights its versatility but also its limitations in numeric regression tasks. Traditional ML models like Gradient Boosting excel in these scenarios because of their specialized architecture and focus on optimizing structured data relationships. T5 might do better with a dataset that included textual descriptions of houses to complement numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Considering the training time and inference time of our T5 model versus the other ML models, do you think the accuracy that our T5 achieve was worth it? why?\n",
    "\n",
    "Considering the training time, I don't think it is worth it. Training was significantly more computationally expensive and time-consuming due to the deep transformer architecture, the necessity to tokenize inputs, and the model’s reliance on backpropagation through a large number of parameters. Additionally, tuning required many epochs and iterations to stabilize. Models like Linear Regression, Random Forest, and Gradient Boosting trained much faster.\n",
    "\n",
    "Considering the inference time, I don't think it is worth it either. Inference involved generating text sequences, which is inherently slower than numerical predictions. This introduces unnecessary latency for real-time applications that don’t involve natural language outputs. Inference was instantaneous for all other ML models as they directly compute predictions from their learned parameters without the need for sequential generation.\n",
    "\n",
    "Regarding the accuracy, the marginal improvement of T5 over simpler models (e.g., compared to Gradient Boosting's validation R-squared of 0.6754, T5's 0.7 was better) does not seem to completely justify the added computational cost and complexity.\n",
    "\n",
    "Regardless, this exercise taught me about transformers and a new model. I liked doing it. Thanks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2WRhEY7VNCX"
   },
   "source": [
    "# Part 5: Submission (Deadline: before class - 9 AM at December 6th, 2024)\n",
    "\n",
    "We expect you to complete the TODOs, run all the code cells, and have the final outputs of those cells displayed in your submission. Your submission file should be a single .ipynb file (openable to Jupyter Notebook and Google Colab).\n",
    "\n",
    "Please submit your file to the course Blackboard."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02f12a69e48f4642b4b2e0344f76e959": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0be7666845884c30a42359b1d99f97e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14bce80ea19c49d7ada1a19c3c597bd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb64c38c5fc4256b07657d2abb7f137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5156e5e50474133bf56410f3cd1cea9",
       "IPY_MODEL_e2975901da744ee894a101511f21c39b",
       "IPY_MODEL_97a3e5f1f22e4d69adeeb8328f3cd60f"
      ],
      "layout": "IPY_MODEL_c89484a7448a478c90687fc856fab969"
     }
    },
    "342a1601026d4695a7c0e632e07261f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ae56dffde6041e190d94a54a068d320": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5035ae64dbef4ea59cb299c357f8cd62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5bbd8f2b54694a019ae4b90331fd0173": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62e7e6c3d16645d581403db1d7bb817e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6303e0595e164a62802df97bf4111933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73203d2aa7a44fc684534fa985d1a15d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b2dfe6ab52d54bb9a2359c106f2bb430",
       "IPY_MODEL_edc81bc49b684b59ba44f94b8c6acf72",
       "IPY_MODEL_dce4d5635b2849aaae38be69c9ccd59f"
      ],
      "layout": "IPY_MODEL_4ae56dffde6041e190d94a54a068d320"
     }
    },
    "73e32194157a452d945ee0c30da2fcb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7415bd0d72364f92b60b9ac68a254746": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce1dfcb10e444f7eac5ef554137baeaa",
       "IPY_MODEL_e16b7041e82343c08b0d41313d2a5531",
       "IPY_MODEL_e9aad2f173b44d0b93f8ab14e27956ef"
      ],
      "layout": "IPY_MODEL_73e32194157a452d945ee0c30da2fcb1"
     }
    },
    "857b63c4f0f347ae8ecde965b945c7da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ae4314e7fb34d07b0d39b736e7af2f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97a3e5f1f22e4d69adeeb8328f3cd60f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c95066f590df481e9708cb09876c4f0b",
      "placeholder": "​",
      "style": "IPY_MODEL_f8936a9ca58b4989836a9b57259c3991",
      "value": " 1.39M/1.39M [00:00&lt;00:00, 4.22MB/s]"
     }
    },
    "9f99b487163f47a78db3a9b26f07ea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9a8fa50eff542ccb00daba6cda0df4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2ae8742877a4fd78faf7a3864e4d34d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2dfe6ab52d54bb9a2359c106f2bb430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14bce80ea19c49d7ada1a19c3c597bd2",
      "placeholder": "​",
      "style": "IPY_MODEL_5bbd8f2b54694a019ae4b90331fd0173",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "b5e6b597947544b09e46c96d26b933d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5156e5e50474133bf56410f3cd1cea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0b5ecfa7f83430da73fbb86504997e7",
      "placeholder": "​",
      "style": "IPY_MODEL_6303e0595e164a62802df97bf4111933",
      "value": "tokenizer.json: 100%"
     }
    },
    "c89484a7448a478c90687fc856fab969": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c95066f590df481e9708cb09876c4f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce1dfcb10e444f7eac5ef554137baeaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddb86aa19cab4c599df8165ca9e2a03a",
      "placeholder": "​",
      "style": "IPY_MODEL_0be7666845884c30a42359b1d99f97e5",
      "value": "spiece.model: 100%"
     }
    },
    "dce4d5635b2849aaae38be69c9ccd59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62e7e6c3d16645d581403db1d7bb817e",
      "placeholder": "​",
      "style": "IPY_MODEL_a9a8fa50eff542ccb00daba6cda0df4d",
      "value": " 2.32k/2.32k [00:00&lt;00:00, 135kB/s]"
     }
    },
    "ddb86aa19cab4c599df8165ca9e2a03a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0b5ecfa7f83430da73fbb86504997e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e16b7041e82343c08b0d41313d2a5531": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_857b63c4f0f347ae8ecde965b945c7da",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5035ae64dbef4ea59cb299c357f8cd62",
      "value": 791656
     }
    },
    "e2975901da744ee894a101511f21c39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ae4314e7fb34d07b0d39b736e7af2f0",
      "max": 1389353,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f99b487163f47a78db3a9b26f07ea20",
      "value": 1389353
     }
    },
    "e9aad2f173b44d0b93f8ab14e27956ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_342a1601026d4695a7c0e632e07261f9",
      "placeholder": "​",
      "style": "IPY_MODEL_02f12a69e48f4642b4b2e0344f76e959",
      "value": " 792k/792k [00:00&lt;00:00, 5.93MB/s]"
     }
    },
    "edc81bc49b684b59ba44f94b8c6acf72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5e6b597947544b09e46c96d26b933d3",
      "max": 2324,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2ae8742877a4fd78faf7a3864e4d34d",
      "value": 2324
     }
    },
    "f8936a9ca58b4989836a9b57259c3991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
